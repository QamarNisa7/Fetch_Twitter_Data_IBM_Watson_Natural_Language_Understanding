{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 508924469818437631\n",
      "...5 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import json\n",
    "import objectpath\n",
    "import pandas as pd\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 \\\n",
    "  import Features, EmotionOptions, ConceptsOptions, CategoriesOptions,SentimentOptions\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_key = \"\"\n",
    "access_secret = \"\"\n",
    "\n",
    "#Watson NLU credentials\n",
    "nlu = NaturalLanguageUnderstandingV1(\n",
    "    version='',\n",
    "    iam_apikey='',\n",
    "    url='https://gateway.watsonplatform.net/natural-language-understanding/api'\n",
    ")\n",
    "#------------\n",
    "\n",
    "screen_name=\"realDonalTrump\"\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    #authorize twitter, initialize tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "alltweets = []\n",
    "\n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "\n",
    "    #save most recent tweets\n",
    "alltweets.extend(new_tweets)\n",
    "\n",
    "    #save the id of the oldest tweet less one\n",
    "oldest = alltweets[-1].id - 1\n",
    "\n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "while len(new_tweets) > 0:\n",
    "    print (\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "        #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "        #update the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    print (\"...%s tweets downloaded so far\" % (len(alltweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tw_body' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cfe495ddfd3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtw_body\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtw_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Link\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'RT'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtw_body\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtwi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtw_body\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtw_body\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tw_body' is not defined"
     ]
    }
   ],
   "source": [
    "outtweets=[\"tweet_id\",\"created date\",\"tweet\",\"tw_type\",\"RT Count\",\"Fav\",\"Tone_Tweet\",\"Tone_Tweet_score\",\"emotion_sad\",\n",
    "           \"emotion_joy\",\"emotion_fear\",\"emotion_disgust\",\"emotion_anger\",\"concept1\",\"concept1_relevance\",\n",
    "           \"concept2\",\"concept2_relevance\",\"category_label\",\"category_score\"]\n",
    "tw_type=\"\"\n",
    "tw_body1=\"\"\n",
    "for tweet in alltweets:\n",
    "    tweet_raw=tweet.text\n",
    "    if 'https' in tweet_raw:\n",
    "        twi=tweet_raw.split(\"https\")\n",
    "        tw_body=twi[0]\n",
    "        tw_type=\"Link\"\n",
    "    if 'RT' in tw_body:\n",
    "        twi=tw_body.split(\"RT\")\n",
    "        tw_body=twi[1]\n",
    "        tw_type=tw_type+\"RT\"\n",
    "    #tw_body=tweet.text.encode(\"utf-8\")\n",
    "    #Do NLU stuff on tweet\n",
    "    try:\n",
    "        tw = nlu.analyze(text=tw_body,\n",
    "        features=Features(emotion=EmotionOptions(),\n",
    "        sentiment=SentimentOptions(),\n",
    "        categories=CategoriesOptions(limit=3),\n",
    "        concepts=ConceptsOptions(limit=3)))\n",
    "        \n",
    "        Tone_Tweet=tw.result['sentiment']['document']['label']\n",
    "        Tone_Tweet_score=tw.result['sentiment']['document']['score']\n",
    "        emotion_sad=tw.result['emotion']['document']['emotion']['sadness']\n",
    "        emotion_joy=tw.result['emotion']['document']['emotion']['joy']\n",
    "        emotion_fear=tw.result['emotion']['document']['emotion']['fear']\n",
    "        emotion_disgust=tw.result['emotion']['document']['emotion']['disgust']\n",
    "        emotion_anger=tw.result['emotion']['document']['emotion']['anger']\n",
    "        concept1=tw.result['concepts'][0]['text']\n",
    "        concept1_relevance=tw.result['concepts'][0]['relevance']\n",
    "        concept2=tw.result['concepts'][1]['text']\n",
    "        concept2_relevance=tw.result['concepts'][1]['relevance']\n",
    "        category_label=tw.result['categories'][0]['label']\n",
    "        category_score=tw.result['categories'][0]['score']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        '''\n",
    "        Tone_Tweet='?'\n",
    "        Tone_Tweet_score='?'\n",
    "        emotion_sad='?'\n",
    "        emotion_joy='?'\n",
    "        emotion_fear='?'\n",
    "        emotion_disgust='?'\n",
    "        emotion_anger='?'\n",
    "        concept1='?'\n",
    "        concept1_relevance='?'\n",
    "        concept2='?'\n",
    "        concept2_relevance='?'\n",
    "        category_label='?'\n",
    "        category_score='?'\n",
    "    '''\n",
    "    #Save other params into data rows\n",
    "\n",
    "    \n",
    "    outtweets.append([tweet.id_str, tweet.created_at, tw_body, tw_type, tweet.retweet_count, tweet.favorite_count,emotion_sad,emotion_joy,emotion_fear,emotion_disgust,emotion_anger,concept1,concept1_relevance,concept2,concept2_relevance,category_label,category_score\n",
    "])\n",
    "print(outtweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "0                                            tweet_id\n",
      "1                                        created date\n",
      "2                                               tweet\n",
      "3                                             tw_type\n",
      "4                                            RT Count\n",
      "5                                                 Fav\n",
      "6                                          Tone_Tweet\n",
      "7                                    Tone_Tweet_score\n",
      "8                                         emotion_sad\n",
      "9                                         emotion_joy\n",
      "10                                       emotion_fear\n",
      "11                                    emotion_disgust\n",
      "12                                      emotion_anger\n",
      "13                                           concept1\n",
      "14                                 concept1_relevance\n",
      "15                                           concept2\n",
      "16                                 concept2_relevance\n",
      "17                                     category_label\n",
      "18                                     category_score\n",
      "19  [1075104139644940290, 2018-12-18 19:02:56, Vie...\n",
      "20  [1074929637220851712, 2018-12-18 07:29:31, Vie...\n",
      "21  [1074398848544620544, 2018-12-16 20:20:21, Vie...\n",
      "22  [1065572060393549824, 2018-11-22 11:45:51, Vie...\n",
      "23  [1034755495595261952, 2018-08-29 10:51:49, Vie...\n",
      "24  [1011925657771790339, 2018-06-27 10:54:12, Vie...\n",
      "25  [1001389184752537600, 2018-05-29 09:06:01, Vie...\n",
      "26  [1001384836949598208, 2018-05-29 08:48:44, Vie...\n",
      "27  [993217905134395393, 2018-05-06 19:56:16,  @IB...\n",
      "28  [986299541522714624, 2018-04-17 17:45:09, View...\n",
      "29  [956063601990754304, 2018-01-24 07:18:20, View...\n",
      "30  [948085001966555136, 2018-01-02 06:54:13,  @IB...\n",
      "31  [943488669175906305, 2017-12-20 14:30:02, View...\n",
      "32  [912252914835615745, 2017-09-25 09:50:18, View...\n",
      "33  [907577267387330560, 2017-09-12 12:10:57,  @de...\n",
      "34  [902095211647598592, 2017-08-28 09:07:13, BWAH...\n",
      "35  [895606025444745216, 2017-08-10 11:21:30, BWAH...\n",
      "36  [895605578327760897, 2017-08-10 11:19:44, haha...\n",
      "37  [890833958929403904, 2017-07-28 07:19:01,  @Na...\n",
      "38  [887253960192643072, 2017-07-18 10:13:23,  @pi...\n",
      "39  [887200823142494208, 2017-07-18 06:42:14,  @fa...\n",
      "40  [877753839750754304, 2017-06-22 05:03:17, Wooh...\n",
      "41  [877752756202684417, 2017-06-22 04:58:59, Wooh...\n",
      "42  [877752650028138496, 2017-06-22 04:58:34, Wooh...\n",
      "43  [874150330220597248, 2017-06-12 06:24:14, Wooh...\n",
      "44  [874148157843795968, 2017-06-12 06:15:36,  @de...\n",
      "45  [874144565971832832, 2017-06-12 06:01:20,  @de...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#write the csv\n",
    "    with open('%s_tweets.csv' % screen_name, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"tweet_id\",\"created date\",\"tweet\",\"tw_type\",\"RT Count\",\"Fav\",\"Tone_Tweet\",\"Tone_Tweet_score\",\"emotion_sad\",\"emotion_joy\",\"emotion_fear\",\"emotion_disgust\",\"emotion_anger\",\"concept1\",\"concept1_relevance\",\"concept2\",\"concept2_relevance\",\"category_label\",\"category_score\"])\n",
    "        writer.writerows(outtweets)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
